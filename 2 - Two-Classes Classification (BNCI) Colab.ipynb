{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Two-Classes Classification (BNCI) Colab.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eegpnTbImFUE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, download datasets (It will take a few minutes. You can comment out some of the files if you want a smaller dataset):"
      ]
    },
    {
      "metadata": {
        "id": "NSi52lWjPNN4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 56
            },
            {
              "item_id": 121
            },
            {
              "item_id": 187
            },
            {
              "item_id": 251
            },
            {
              "item_id": 316
            },
            {
              "item_id": 381
            },
            {
              "item_id": 445
            },
            {
              "item_id": 527
            },
            {
              "item_id": 584
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 7148
        },
        "outputId": "e7a72e5e-ab3e-406e-a7db-4a8027d8e4a4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520641929270,
          "user_tz": 300,
          "elapsed": 154891,
          "user": {
            "displayName": "Naoto Hieda",
            "photoUrl": "//lh5.googleusercontent.com/-ip0di8FUDgg/AAAAAAAAAAI/AAAAAAAADQw/Tl2aHp0Lnac/s50-c-k-no/photo.jpg",
            "userId": "115529134129143068859"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S02T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S02E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S03T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S03E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S04T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S04E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S05T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S05E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S06T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S06E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S07T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S07E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S08T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S08E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S09T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S09E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S10T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S10E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S11T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S11E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S12T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S12E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S13T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S13E.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S14T.mat\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S14E.mat"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-03-10 00:30:31--  http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01T.mat\r\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.204.35\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.204.35|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/002-2014/S01T.mat [following]\n",
            "--2018-03-10 00:30:32--  https://lampx.tugraz.at/~bci/database/002-2014/S01T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.207\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39794870 (38M)\n",
            "Saving to: ‘S01T.mat’\n",
            "\n",
            "S01T.mat            100%[===================>]  37.95M  10.3MB/s    in 4.8s    \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dur3RW3pmWfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Move files to a separate folder:"
      ]
    },
    {
      "metadata": {
        "id": "Erg5PSb_PXi2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir BBCIData\n",
        "!mv *.mat BBCIData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7CK51BEmbN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install dependencies (braindecode & pytorch):"
      ]
    },
    {
      "metadata": {
        "id": "hxBTOWbvPjpP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install braindecode -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LxVQ9HYqQCSO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ejLdMTpjmiRY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's load data.\n",
        "\n",
        "We read the file for the desired subject, and parse the data to extract:\n",
        "- samplingRate\n",
        "- trialLength\n",
        "- X, a M x N x K matrix, which stands for trial x chan x samples\n",
        "    - the actual values are 160 x 15 x 2560\n",
        "- y, a M vector containing the labels {0,1}\n",
        "\n",
        "ref: Dataset description: https://lampx.tugraz.at/~bci/database/002-2014/description.pdf"
      ]
    },
    {
      "metadata": {
        "id": "DpLUMPuqN5CZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d52775ee-e361-430e-c75e-f2de9a54475a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520647192303,
          "user_tz": 300,
          "elapsed": 10381,
          "user": {
            "displayName": "Naoto Hieda",
            "photoUrl": "//lh5.googleusercontent.com/-ip0di8FUDgg/AAAAAAAAAAI/AAAAAAAADQw/Tl2aHp0Lnac/s50-c-k-no/photo.jpg",
            "userId": "115529134129143068859"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# prepare data containers\n",
        "y = []\n",
        "X = []\n",
        "\n",
        "folder = \"BBCIData\"\n",
        "\n",
        "for f in listdir(folder):\n",
        "    # read file\n",
        "    d1T = sio.loadmat(folder + "/" + f)\n",
        "    \n",
        "    samplingRate = d1T['data'][0][0][0][0][3][0][0]\n",
        "    trialLength = 5*samplingRate\n",
        "\n",
        "\n",
        "    # run through all training runs\n",
        "    for run in range(len(d1T['data'][0])):\n",
        "        y.append(d1T['data'][0][run][0][0][2][0]) # labels\n",
        "        timestamps = d1T['data'][0][run][0][0][1][0] # timestamps\n",
        "        rawData = d1T['data'][0][run][0][0][0].transpose() # chan x data\n",
        "\n",
        "        # parse out data based on timestamps\n",
        "        for start in timestamps:\n",
        "            end = start + trialLength\n",
        "            X.append(rawData[:,start:end]) #15 x 2560\n",
        "\n",
        "    del rawData\n",
        "    del d1T\n",
        "\n",
        "# arrange data into numpy arrays\n",
        "# also torch expect float32 for samples\n",
        "# and int64 for labels {0,1}\n",
        "X = np.array(X).astype(np.float32)\n",
        "y = (np.array(y).flatten()-1).astype(np.int64)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2240, 15, 2560)\n",
            "(2240,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ICtnURjeo3vf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the models:"
      ]
    },
    {
      "metadata": {
        "id": "6PUAO5bSPfN3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from braindecode.datautil.signal_target import SignalAndTarget\n",
        "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
        "from torch import nn\n",
        "from braindecode.torch_ext.util import set_random_seeds    \n",
        "from torch import optim\n",
        "import torch\n",
        "\n",
        "idx = np.random.permutation(X.shape[0])\n",
        "\n",
        "X = X[idx,:,:]\n",
        "y = y[idx]\n",
        "\n",
        "nb_train_trials = int(np.floor(5/8*X.shape[0]))\n",
        "\n",
        "\n",
        "train_set = SignalAndTarget(X[:nb_train_trials], y=y[:nb_train_trials])\n",
        "test_set = SignalAndTarget(X[nb_train_trials:], y=y[nb_train_trials:])\n",
        "\n",
        "# Set if you want to use GPU\n",
        "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
        "cuda = torch.cuda.is_available()\n",
        "set_random_seeds(seed=20170629, cuda=cuda)\n",
        "n_classes = 2\n",
        "in_chans = train_set.X.shape[1]\n",
        "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
        "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
        "                        input_time_length=train_set.X.shape[2],\n",
        "                        final_conv_length='auto').create_network()\n",
        "if cuda:\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5De8ILppIB6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load optimizer. You can find hyperparameters in the link below.  \n",
        "http://pytorch.org/docs/master/optim.html"
      ]
    },
    {
      "metadata": {
        "id": "qpYOwKBdpPcS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lvliRV3dpazA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally start training:"
      ]
    },
    {
      "metadata": {
        "id": "qhG6M1RZQWAe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 65
            },
            {
              "item_id": 101
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 4357
        },
        "outputId": "e9e89aa6-a02b-4b9d-86af-057a245bd073",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520646196083,
          "user_tz": 300,
          "elapsed": 78165,
          "user": {
            "displayName": "Naoto Hieda",
            "photoUrl": "//lh5.googleusercontent.com/-ip0di8FUDgg/AAAAAAAAAAI/AAAAAAAADQw/Tl2aHp0Lnac/s50-c-k-no/photo.jpg",
            "userId": "115529134129143068859"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
        "from braindecode.datautil.iterators import get_balanced_batches\n",
        "import torch.nn.functional as F\n",
        "from numpy.random import RandomState\n",
        "rng = RandomState(None)\n",
        "#rng = RandomState((2017,6,30))\n",
        "for i_epoch in range(50):\n",
        "    i_trials_in_batch = get_balanced_batches(len(train_set.X), rng, shuffle=True,\n",
        "                                            batch_size=32)\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    for i_trials in i_trials_in_batch:\n",
        "        # Have to add empty fourth dimension to X\n",
        "        batch_X = train_set.X[i_trials][:,:,:,None]\n",
        "        batch_y = train_set.y[i_trials]\n",
        "        net_in = np_to_var(batch_X)\n",
        "        if cuda:\n",
        "            net_in = net_in.cuda()\n",
        "        net_target = np_to_var(batch_y)\n",
        "        if cuda:\n",
        "            net_target = net_target.cuda()\n",
        "        # Remove gradients of last backward pass from all parameters\n",
        "        optimizer.zero_grad()\n",
        "        # Compute outputs of the network\n",
        "        outputs = model(net_in)\n",
        "        # Compute the loss\n",
        "        loss = F.nll_loss(outputs, net_target)\n",
        "        # Do the backpropagation\n",
        "        loss.backward()\n",
        "        # Update parameters with the optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print some statistics each epoch\n",
        "    model.eval()\n",
        "    print(\"Epoch {:d}\".format(i_epoch))\n",
        "    for setname, dataset in (('Train', train_set), ('Test', test_set)):\n",
        "        i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, batch_size=32, shuffle=False)\n",
        "        outputs = []\n",
        "        net_targets = []\n",
        "        for i_trials in i_trials_in_batch:\n",
        "            batch_X = train_set.X[i_trials][:,:,:,None]\n",
        "            batch_y = train_set.y[i_trials]\n",
        "            \n",
        "            net_in = np_to_var(batch_X)\n",
        "            if cuda:\n",
        "                net_in = net_in.cuda()\n",
        "            net_target = np_to_var(batch_y)\n",
        "            if cuda:\n",
        "                net_target = net_target.cuda()\n",
        "            net_target = var_to_np(net_target)\n",
        "            output = var_to_np(model(net_in))\n",
        "            outputs.append(output)\n",
        "            net_targets.append(net_target)\n",
        "        net_targets = np_to_var(np.concatenate(net_targets))\n",
        "        outputs = np_to_var(np.concatenate(outputs))\n",
        "        loss = F.nll_loss(outputs, net_targets)\n",
        "        print(\"{:6s} Loss: {:.5f}\".format(\n",
        "            setname, float(var_to_np(loss))))\n",
        "        predicted_labels = np.argmax(var_to_np(outputs), axis=1)\n",
        "        accuracy = np.mean(dataset.y  == predicted_labels)\n",
        "        print(\"{:6s} Accuracy: {:.1f}%\".format(\n",
        "            setname, accuracy * 100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train  Loss: 0.72573\n",
            "Train  Accuracy: 55.4%\n",
            "Test   Loss: 0.71195\n",
            "Test   Accuracy: 49.6%\n",
            "Epoch 1\n",
            "Train  Loss: 0.65435\n",
            "Train  Accuracy: 62.2%\n",
            "Test   Loss: 0.64485\n",
            "Test   Accuracy: 48.8%\n",
            "Epoch 2\n",
            "Train  Loss: 0.66047\n",
            "Train  Accuracy: 61.1%\n",
            "Test   Loss: 0.66806\n",
            "Test   Accuracy: 49.0%\n",
            "Epoch 3\n",
            "Train  Loss: 0.65374\n",
            "Train  Accuracy: 61.1%\n",
            "Test   Loss: 0.66172\n",
            "Test   Accuracy: 49.3%\n",
            "Epoch 4\n",
            "Train  Loss: 0.76140\n",
            "Train  Accuracy: 60.6%\n",
            "Test   Loss: 0.77328\n",
            "Test   Accuracy: 51.0%\n",
            "Epoch 5\n",
            "Train  Loss: 0.69497\n",
            "Train  Accuracy: 62.1%\n",
            "Test   Loss: 0.69986\n",
            "Test   Accuracy: 49.8%\n",
            "Epoch 6\n",
            "Train  Loss: 0.61175\n",
            "Train  Accuracy: 65.6%\n",
            "Test   Loss: 0.62332\n",
            "Test   Accuracy: 49.3%\n",
            "Epoch 7\n",
            "Train  Loss: 0.58174\n",
            "Train  Accuracy: 68.9%\n",
            "Test   Loss: 0.57760\n",
            "Test   Accuracy: 49.3%\n",
            "Epoch 8\n",
            "Train  Loss: 0.57410\n",
            "Train  Accuracy: 68.3%\n",
            "Test   Loss: 0.57376\n",
            "Test   Accuracy: 49.4%\n",
            "Epoch 9\n",
            "Train  Loss: 0.60040\n",
            "Train  Accuracy: 66.1%\n",
            "Test   Loss: 0.57964\n",
            "Test   Accuracy: 47.3%\n",
            "Epoch 10\n",
            "Train  Loss: 0.63183\n",
            "Train  Accuracy: 63.8%\n",
            "Test   Loss: 0.62472\n",
            "Test   Accuracy: 50.0%\n",
            "Epoch 11\n",
            "Train  Loss: 0.61913\n",
            "Train  Accuracy: 65.1%\n",
            "Test   Loss: 0.60059\n",
            "Test   Accuracy: 47.1%\n",
            "Epoch 12\n",
            "Train  Loss: 0.73397\n",
            "Train  Accuracy: 64.4%\n",
            "Test   Loss: 0.76104\n",
            "Test   Accuracy: 52.7%\n",
            "Epoch 13\n",
            "Train  Loss: 0.55054\n",
            "Train  Accuracy: 71.9%\n",
            "Test   Loss: 0.54333\n",
            "Test   Accuracy: 49.9%\n",
            "Epoch 14\n",
            "Train  Loss: 0.61816\n",
            "Train  Accuracy: 66.1%\n",
            "Test   Loss: 0.61443\n",
            "Test   Accuracy: 49.0%\n",
            "Epoch 15\n",
            "Train  Loss: 0.59572\n",
            "Train  Accuracy: 65.8%\n",
            "Test   Loss: 0.57343\n",
            "Test   Accuracy: 48.6%\n",
            "Epoch 16\n",
            "Train  Loss: 0.53755\n",
            "Train  Accuracy: 72.0%\n",
            "Test   Loss: 0.53409\n",
            "Test   Accuracy: 49.2%\n",
            "Epoch 17\n",
            "Train  Loss: 0.59368\n",
            "Train  Accuracy: 67.4%\n",
            "Test   Loss: 0.58939\n",
            "Test   Accuracy: 48.6%\n",
            "Epoch 18\n",
            "Train  Loss: 0.53917\n",
            "Train  Accuracy: 73.2%\n",
            "Test   Loss: 0.54144\n",
            "Test   Accuracy: 51.1%\n",
            "Epoch 19\n",
            "Train  Loss: 0.54877\n",
            "Train  Accuracy: 70.9%\n",
            "Test   Loss: 0.55492\n",
            "Test   Accuracy: 52.0%\n",
            "Epoch 20\n",
            "Train  Loss: 0.66616\n",
            "Train  Accuracy: 62.1%\n",
            "Test   Loss: 0.63429\n",
            "Test   Accuracy: 47.4%\n",
            "Epoch 21\n",
            "Train  Loss: 0.64772\n",
            "Train  Accuracy: 65.1%\n",
            "Test   Loss: 0.65618\n",
            "Test   Accuracy: 49.2%\n",
            "Epoch 22\n",
            "Train  Loss: 0.52790\n",
            "Train  Accuracy: 72.4%\n",
            "Test   Loss: 0.52912\n",
            "Test   Accuracy: 49.3%\n",
            "Epoch 23\n",
            "Train  Loss: 0.51868\n",
            "Train  Accuracy: 73.7%\n",
            "Test   Loss: 0.51903\n",
            "Test   Accuracy: 51.1%\n",
            "Epoch 24\n",
            "Train  Loss: 0.57672\n",
            "Train  Accuracy: 71.1%\n",
            "Test   Loss: 0.58098\n",
            "Test   Accuracy: 49.6%\n",
            "Epoch 25\n",
            "Train  Loss: 0.51559\n",
            "Train  Accuracy: 74.6%\n",
            "Test   Loss: 0.50644\n",
            "Test   Accuracy: 48.7%\n",
            "Epoch 26\n",
            "Train  Loss: 0.49508\n",
            "Train  Accuracy: 75.5%\n",
            "Test   Loss: 0.49199\n",
            "Test   Accuracy: 48.7%\n",
            "Epoch 27\n",
            "Train  Loss: 0.48998\n",
            "Train  Accuracy: 76.1%\n",
            "Test   Loss: 0.48598\n",
            "Test   Accuracy: 49.4%\n",
            "Epoch 28\n",
            "Train  Loss: 0.48288\n",
            "Train  Accuracy: 76.3%\n",
            "Test   Loss: 0.48856\n",
            "Test   Accuracy: 50.1%\n",
            "Epoch 29\n",
            "Train  Loss: 0.50852\n",
            "Train  Accuracy: 73.5%\n",
            "Test   Loss: 0.50352\n",
            "Test   Accuracy: 49.6%\n",
            "Epoch 30\n",
            "Train  Loss: 0.50894\n",
            "Train  Accuracy: 74.7%\n",
            "Test   Loss: 0.49076\n",
            "Test   Accuracy: 49.4%\n",
            "Epoch 31\n",
            "Train  Loss: 0.52614\n",
            "Train  Accuracy: 73.9%\n",
            "Test   Loss: 0.53077\n",
            "Test   Accuracy: 51.3%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32\n",
            "Train  Loss: 0.58961\n",
            "Train  Accuracy: 68.9%\n",
            "Test   Loss: 0.59968\n",
            "Test   Accuracy: 50.2%\n",
            "Epoch 33\n",
            "Train  Loss: 0.54916\n",
            "Train  Accuracy: 70.6%\n",
            "Test   Loss: 0.56440\n",
            "Test   Accuracy: 50.8%\n",
            "Epoch 34\n",
            "Train  Loss: 0.48990\n",
            "Train  Accuracy: 75.1%\n",
            "Test   Loss: 0.50170\n",
            "Test   Accuracy: 49.8%\n",
            "Epoch 35\n",
            "Train  Loss: 0.46224\n",
            "Train  Accuracy: 77.6%\n",
            "Test   Loss: 0.47194\n",
            "Test   Accuracy: 49.6%\n",
            "Epoch 36\n",
            "Train  Loss: 0.46028\n",
            "Train  Accuracy: 78.6%\n",
            "Test   Loss: 0.45661\n",
            "Test   Accuracy: 48.7%\n",
            "Epoch 37\n",
            "Train  Loss: 0.45067\n",
            "Train  Accuracy: 80.1%\n",
            "Test   Loss: 0.44671\n",
            "Test   Accuracy: 47.1%\n",
            "Epoch 38\n",
            "Train  Loss: 0.46178\n",
            "Train  Accuracy: 77.4%\n",
            "Test   Loss: 0.47533\n",
            "Test   Accuracy: 49.0%\n",
            "Epoch 39\n",
            "Train  Loss: 0.51030\n",
            "Train  Accuracy: 75.1%\n",
            "Test   Loss: 0.52092\n",
            "Test   Accuracy: 50.0%\n",
            "Epoch 40\n",
            "Train  Loss: 0.45420\n",
            "Train  Accuracy: 79.6%\n",
            "Test   Loss: 0.45321\n",
            "Test   Accuracy: 49.3%\n",
            "Epoch 41\n",
            "Train  Loss: 0.48343\n",
            "Train  Accuracy: 76.6%\n",
            "Test   Loss: 0.48765\n",
            "Test   Accuracy: 50.6%\n",
            "Epoch 42\n",
            "Train  Loss: 0.47272\n",
            "Train  Accuracy: 76.4%\n",
            "Test   Loss: 0.47233\n",
            "Test   Accuracy: 48.2%\n",
            "Epoch 43\n",
            "Train  Loss: 0.51000\n",
            "Train  Accuracy: 73.6%\n",
            "Test   Loss: 0.50334\n",
            "Test   Accuracy: 48.5%\n",
            "Epoch 44\n",
            "Train  Loss: 0.44103\n",
            "Train  Accuracy: 79.7%\n",
            "Test   Loss: 0.44765\n",
            "Test   Accuracy: 47.9%\n",
            "Epoch 45\n",
            "Train  Loss: 0.43916\n",
            "Train  Accuracy: 80.2%\n",
            "Test   Loss: 0.44658\n",
            "Test   Accuracy: 48.7%\n",
            "Epoch 46\n",
            "Train  Loss: 0.42295\n",
            "Train  Accuracy: 81.8%\n",
            "Test   Loss: 0.43008\n",
            "Test   Accuracy: 47.5%\n",
            "Epoch 47\n",
            "Train  Loss: 0.43720\n",
            "Train  Accuracy: 78.7%\n",
            "Test   Loss: 0.43922\n",
            "Test   Accuracy: 50.1%\n",
            "Epoch 48\n",
            "Train  Loss: 0.42250\n",
            "Train  Accuracy: 81.4%\n",
            "Test   Loss: 0.41817\n",
            "Test   Accuracy: 48.2%\n",
            "Epoch 49\n",
            "Train  Loss: 0.41523\n",
            "Train  Accuracy: 82.3%\n",
            "Test   Loss: 0.41426\n",
            "Test   Accuracy: 48.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aR1blMkOQZLk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
