{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eegpnTbImFUE"
   },
   "source": [
    "First, download datasets (It will take a few minutes. You can comment out some of the files if you want a smaller dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 7148,
     "output_extras": [
      {
       "item_id": 56
      },
      {
       "item_id": 121
      },
      {
       "item_id": 187
      },
      {
       "item_id": 251
      },
      {
       "item_id": 316
      },
      {
       "item_id": 381
      },
      {
       "item_id": 445
      },
      {
       "item_id": 527
      },
      {
       "item_id": 584
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 154891,
     "status": "ok",
     "timestamp": 1520641929270,
     "user": {
      "displayName": "Naoto Hieda",
      "photoUrl": "//lh5.googleusercontent.com/-ip0di8FUDgg/AAAAAAAAAAI/AAAAAAAADQw/Tl2aHp0Lnac/s50-c-k-no/photo.jpg",
      "userId": "115529134129143068859"
     },
     "user_tz": 300
    },
    "id": "NSi52lWjPNN4",
    "outputId": "e7a72e5e-ab3e-406e-a7db-4a8027d8e4a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-10 00:30:31--  http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01T.mat\r\n",
      "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.204.35\n",
      "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.204.35|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://lampx.tugraz.at/~bci/database/002-2014/S01T.mat [following]\n",
      "--2018-03-10 00:30:32--  https://lampx.tugraz.at/~bci/database/002-2014/S01T.mat\n",
      "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.207\n",
      "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39794870 (38M)\n",
      "Saving to: ‘S01T.mat’\n",
      "\n",
      "S01T.mat            100%[===================>]  37.95M  10.3MB/s    in 4.8s    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S01E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S02T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S02E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S03T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S03E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S04T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S04E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S05T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S05E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S06T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S06E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S07T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S07E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S08T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S08E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S09T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S09E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S10T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S10E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S11T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S11E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S12T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S12E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S13T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S13E.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S14T.mat\n",
    "!wget http://bnci-horizon-2020.eu/database/data-sets/002-2014/S14E.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dur3RW3pmWfv"
   },
   "source": [
    "Move files to a separate folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Erg5PSb_PXi2"
   },
   "outputs": [],
   "source": [
    "!mkdir BBCIData\n",
    "!mv *.mat BBCIData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7CK51BEmbN5"
   },
   "source": [
    "Install dependencies (braindecode & pytorch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hxBTOWbvPjpP"
   },
   "outputs": [],
   "source": [
    "!pip install braindecode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LxVQ9HYqQCSO"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejLdMTpjmiRY"
   },
   "source": [
    "Now, let's load data.\n",
    "\n",
    "We read the file for the desired subject, and parse the data to extract:\n",
    "- samplingRate\n",
    "- trialLength\n",
    "- X, a M x N x K matrix, which stands for trial x chan x samples\n",
    "    - the actual values are 160 x 15 x 2560\n",
    "- y, a M vector containing the labels {0,1}\n",
    "\n",
    "ref: Dataset description: https://lampx.tugraz.at/~bci/database/002-2014/description.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 10381,
     "status": "ok",
     "timestamp": 1520647192303,
     "user": {
      "displayName": "Naoto Hieda",
      "photoUrl": "//lh5.googleusercontent.com/-ip0di8FUDgg/AAAAAAAAAAI/AAAAAAAADQw/Tl2aHp0Lnac/s50-c-k-no/photo.jpg",
      "userId": "115529134129143068859"
     },
     "user_tz": 300
    },
    "id": "DpLUMPuqN5CZ",
    "outputId": "d52775ee-e361-430e-c75e-f2de9a54475a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 15, 2560)\n",
      "(2240,)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# prepare data containers\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "folder = \"BBCIData\"\n",
    "\n",
    "for f in listdir(folder):\n",
    "    # read file\n",
    "    d1T = sio.loadmat(folder + \"/\" + f)\n",
    "    \n",
    "    samplingRate = d1T['data'][0][0][0][0][3][0][0]\n",
    "    trialLength = 5*samplingRate\n",
    "\n",
    "\n",
    "    # run through all training runs\n",
    "    for run in range(len(d1T['data'][0])):\n",
    "        y.append(d1T['data'][0][run][0][0][2][0]) # labels\n",
    "        timestamps = d1T['data'][0][run][0][0][1][0] # timestamps\n",
    "        rawData = d1T['data'][0][run][0][0][0].transpose() # chan x data\n",
    "\n",
    "        # parse out data based on timestamps\n",
    "        for start in timestamps:\n",
    "            end = start + trialLength\n",
    "            X.append(rawData[:,start:end]) #15 x 2560\n",
    "\n",
    "    del rawData\n",
    "    del d1T\n",
    "\n",
    "# arrange data into numpy arrays\n",
    "# also torch expect float32 for samples\n",
    "# and int64 for labels {0,1}\n",
    "X = np.array(X).astype(np.float32)\n",
    "y = (np.array(y).flatten()-1).astype(np.int64)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICtnURjeo3vf"
   },
   "source": [
    "Load the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6PUAO5bSPfN3"
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds    \n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "idx = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[idx,:,:]\n",
    "y = y[idx]\n",
    "\n",
    "nb_train_trials = int(np.floor(5/8*X.shape[0]))\n",
    "\n",
    "\n",
    "train_set = SignalAndTarget(X[:nb_train_trials], y=y[:nb_train_trials])\n",
    "test_set = SignalAndTarget(X[nb_train_trials:], y=y[nb_train_trials:])\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = torch.cuda.is_available()\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=train_set.X.shape[2],\n",
    "                        final_conv_length='auto').create_network()\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5De8ILppIB6"
   },
   "source": [
    "Load optimizer. You can find hyperparameters in the link below.  \n",
    "http://pytorch.org/docs/master/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qpYOwKBdpPcS"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvliRV3dpazA"
   },
   "source": [
    "Finally start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 4357,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 65
      },
      {
       "item_id": 101
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 78165,
     "status": "ok",
     "timestamp": 1520646196083,
     "user": {
      "displayName": "Naoto Hieda",
      "photoUrl": "//lh5.googleusercontent.com/-ip0di8FUDgg/AAAAAAAAAAI/AAAAAAAADQw/Tl2aHp0Lnac/s50-c-k-no/photo.jpg",
      "userId": "115529134129143068859"
     },
     "user_tz": 300
    },
    "id": "qhG6M1RZQWAe",
    "outputId": "e9e89aa6-a02b-4b9d-86af-057a245bd073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train  Loss: 0.72573\n",
      "Train  Accuracy: 55.4%\n",
      "Test   Loss: 0.71195\n",
      "Test   Accuracy: 49.6%\n",
      "Epoch 1\n",
      "Train  Loss: 0.65435\n",
      "Train  Accuracy: 62.2%\n",
      "Test   Loss: 0.64485\n",
      "Test   Accuracy: 48.8%\n",
      "Epoch 2\n",
      "Train  Loss: 0.66047\n",
      "Train  Accuracy: 61.1%\n",
      "Test   Loss: 0.66806\n",
      "Test   Accuracy: 49.0%\n",
      "Epoch 3\n",
      "Train  Loss: 0.65374\n",
      "Train  Accuracy: 61.1%\n",
      "Test   Loss: 0.66172\n",
      "Test   Accuracy: 49.3%\n",
      "Epoch 4\n",
      "Train  Loss: 0.76140\n",
      "Train  Accuracy: 60.6%\n",
      "Test   Loss: 0.77328\n",
      "Test   Accuracy: 51.0%\n",
      "Epoch 5\n",
      "Train  Loss: 0.69497\n",
      "Train  Accuracy: 62.1%\n",
      "Test   Loss: 0.69986\n",
      "Test   Accuracy: 49.8%\n",
      "Epoch 6\n",
      "Train  Loss: 0.61175\n",
      "Train  Accuracy: 65.6%\n",
      "Test   Loss: 0.62332\n",
      "Test   Accuracy: 49.3%\n",
      "Epoch 7\n",
      "Train  Loss: 0.58174\n",
      "Train  Accuracy: 68.9%\n",
      "Test   Loss: 0.57760\n",
      "Test   Accuracy: 49.3%\n",
      "Epoch 8\n",
      "Train  Loss: 0.57410\n",
      "Train  Accuracy: 68.3%\n",
      "Test   Loss: 0.57376\n",
      "Test   Accuracy: 49.4%\n",
      "Epoch 9\n",
      "Train  Loss: 0.60040\n",
      "Train  Accuracy: 66.1%\n",
      "Test   Loss: 0.57964\n",
      "Test   Accuracy: 47.3%\n",
      "Epoch 10\n",
      "Train  Loss: 0.63183\n",
      "Train  Accuracy: 63.8%\n",
      "Test   Loss: 0.62472\n",
      "Test   Accuracy: 50.0%\n",
      "Epoch 11\n",
      "Train  Loss: 0.61913\n",
      "Train  Accuracy: 65.1%\n",
      "Test   Loss: 0.60059\n",
      "Test   Accuracy: 47.1%\n",
      "Epoch 12\n",
      "Train  Loss: 0.73397\n",
      "Train  Accuracy: 64.4%\n",
      "Test   Loss: 0.76104\n",
      "Test   Accuracy: 52.7%\n",
      "Epoch 13\n",
      "Train  Loss: 0.55054\n",
      "Train  Accuracy: 71.9%\n",
      "Test   Loss: 0.54333\n",
      "Test   Accuracy: 49.9%\n",
      "Epoch 14\n",
      "Train  Loss: 0.61816\n",
      "Train  Accuracy: 66.1%\n",
      "Test   Loss: 0.61443\n",
      "Test   Accuracy: 49.0%\n",
      "Epoch 15\n",
      "Train  Loss: 0.59572\n",
      "Train  Accuracy: 65.8%\n",
      "Test   Loss: 0.57343\n",
      "Test   Accuracy: 48.6%\n",
      "Epoch 16\n",
      "Train  Loss: 0.53755\n",
      "Train  Accuracy: 72.0%\n",
      "Test   Loss: 0.53409\n",
      "Test   Accuracy: 49.2%\n",
      "Epoch 17\n",
      "Train  Loss: 0.59368\n",
      "Train  Accuracy: 67.4%\n",
      "Test   Loss: 0.58939\n",
      "Test   Accuracy: 48.6%\n",
      "Epoch 18\n",
      "Train  Loss: 0.53917\n",
      "Train  Accuracy: 73.2%\n",
      "Test   Loss: 0.54144\n",
      "Test   Accuracy: 51.1%\n",
      "Epoch 19\n",
      "Train  Loss: 0.54877\n",
      "Train  Accuracy: 70.9%\n",
      "Test   Loss: 0.55492\n",
      "Test   Accuracy: 52.0%\n",
      "Epoch 20\n",
      "Train  Loss: 0.66616\n",
      "Train  Accuracy: 62.1%\n",
      "Test   Loss: 0.63429\n",
      "Test   Accuracy: 47.4%\n",
      "Epoch 21\n",
      "Train  Loss: 0.64772\n",
      "Train  Accuracy: 65.1%\n",
      "Test   Loss: 0.65618\n",
      "Test   Accuracy: 49.2%\n",
      "Epoch 22\n",
      "Train  Loss: 0.52790\n",
      "Train  Accuracy: 72.4%\n",
      "Test   Loss: 0.52912\n",
      "Test   Accuracy: 49.3%\n",
      "Epoch 23\n",
      "Train  Loss: 0.51868\n",
      "Train  Accuracy: 73.7%\n",
      "Test   Loss: 0.51903\n",
      "Test   Accuracy: 51.1%\n",
      "Epoch 24\n",
      "Train  Loss: 0.57672\n",
      "Train  Accuracy: 71.1%\n",
      "Test   Loss: 0.58098\n",
      "Test   Accuracy: 49.6%\n",
      "Epoch 25\n",
      "Train  Loss: 0.51559\n",
      "Train  Accuracy: 74.6%\n",
      "Test   Loss: 0.50644\n",
      "Test   Accuracy: 48.7%\n",
      "Epoch 26\n",
      "Train  Loss: 0.49508\n",
      "Train  Accuracy: 75.5%\n",
      "Test   Loss: 0.49199\n",
      "Test   Accuracy: 48.7%\n",
      "Epoch 27\n",
      "Train  Loss: 0.48998\n",
      "Train  Accuracy: 76.1%\n",
      "Test   Loss: 0.48598\n",
      "Test   Accuracy: 49.4%\n",
      "Epoch 28\n",
      "Train  Loss: 0.48288\n",
      "Train  Accuracy: 76.3%\n",
      "Test   Loss: 0.48856\n",
      "Test   Accuracy: 50.1%\n",
      "Epoch 29\n",
      "Train  Loss: 0.50852\n",
      "Train  Accuracy: 73.5%\n",
      "Test   Loss: 0.50352\n",
      "Test   Accuracy: 49.6%\n",
      "Epoch 30\n",
      "Train  Loss: 0.50894\n",
      "Train  Accuracy: 74.7%\n",
      "Test   Loss: 0.49076\n",
      "Test   Accuracy: 49.4%\n",
      "Epoch 31\n",
      "Train  Loss: 0.52614\n",
      "Train  Accuracy: 73.9%\n",
      "Test   Loss: 0.53077\n",
      "Test   Accuracy: 51.3%\n",
      "Epoch 32\n",
      "Train  Loss: 0.58961\n",
      "Train  Accuracy: 68.9%\n",
      "Test   Loss: 0.59968\n",
      "Test   Accuracy: 50.2%\n",
      "Epoch 33\n",
      "Train  Loss: 0.54916\n",
      "Train  Accuracy: 70.6%\n",
      "Test   Loss: 0.56440\n",
      "Test   Accuracy: 50.8%\n",
      "Epoch 34\n",
      "Train  Loss: 0.48990\n",
      "Train  Accuracy: 75.1%\n",
      "Test   Loss: 0.50170\n",
      "Test   Accuracy: 49.8%\n",
      "Epoch 35\n",
      "Train  Loss: 0.46224\n",
      "Train  Accuracy: 77.6%\n",
      "Test   Loss: 0.47194\n",
      "Test   Accuracy: 49.6%\n",
      "Epoch 36\n",
      "Train  Loss: 0.46028\n",
      "Train  Accuracy: 78.6%\n",
      "Test   Loss: 0.45661\n",
      "Test   Accuracy: 48.7%\n",
      "Epoch 37\n",
      "Train  Loss: 0.45067\n",
      "Train  Accuracy: 80.1%\n",
      "Test   Loss: 0.44671\n",
      "Test   Accuracy: 47.1%\n",
      "Epoch 38\n",
      "Train  Loss: 0.46178\n",
      "Train  Accuracy: 77.4%\n",
      "Test   Loss: 0.47533\n",
      "Test   Accuracy: 49.0%\n",
      "Epoch 39\n",
      "Train  Loss: 0.51030\n",
      "Train  Accuracy: 75.1%\n",
      "Test   Loss: 0.52092\n",
      "Test   Accuracy: 50.0%\n",
      "Epoch 40\n",
      "Train  Loss: 0.45420\n",
      "Train  Accuracy: 79.6%\n",
      "Test   Loss: 0.45321\n",
      "Test   Accuracy: 49.3%\n",
      "Epoch 41\n",
      "Train  Loss: 0.48343\n",
      "Train  Accuracy: 76.6%\n",
      "Test   Loss: 0.48765\n",
      "Test   Accuracy: 50.6%\n",
      "Epoch 42\n",
      "Train  Loss: 0.47272\n",
      "Train  Accuracy: 76.4%\n",
      "Test   Loss: 0.47233\n",
      "Test   Accuracy: 48.2%\n",
      "Epoch 43\n",
      "Train  Loss: 0.51000\n",
      "Train  Accuracy: 73.6%\n",
      "Test   Loss: 0.50334\n",
      "Test   Accuracy: 48.5%\n",
      "Epoch 44\n",
      "Train  Loss: 0.44103\n",
      "Train  Accuracy: 79.7%\n",
      "Test   Loss: 0.44765\n",
      "Test   Accuracy: 47.9%\n",
      "Epoch 45\n",
      "Train  Loss: 0.43916\n",
      "Train  Accuracy: 80.2%\n",
      "Test   Loss: 0.44658\n",
      "Test   Accuracy: 48.7%\n",
      "Epoch 46\n",
      "Train  Loss: 0.42295\n",
      "Train  Accuracy: 81.8%\n",
      "Test   Loss: 0.43008\n",
      "Test   Accuracy: 47.5%\n",
      "Epoch 47\n",
      "Train  Loss: 0.43720\n",
      "Train  Accuracy: 78.7%\n",
      "Test   Loss: 0.43922\n",
      "Test   Accuracy: 50.1%\n",
      "Epoch 48\n",
      "Train  Loss: 0.42250\n",
      "Train  Accuracy: 81.4%\n",
      "Test   Loss: 0.41817\n",
      "Test   Accuracy: 48.2%\n",
      "Epoch 49\n",
      "Train  Loss: 0.41523\n",
      "Train  Accuracy: 82.3%\n",
      "Test   Loss: 0.41426\n",
      "Test   Accuracy: 48.6%\n"
     ]
    }
   ],
   "source": [
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from braindecode.datautil.iterators import get_balanced_batches\n",
    "import torch.nn.functional as F\n",
    "from numpy.random import RandomState\n",
    "rng = RandomState(None)\n",
    "#rng = RandomState((2017,6,30))\n",
    "for i_epoch in range(50):\n",
    "    i_trials_in_batch = get_balanced_batches(len(train_set.X), rng, shuffle=True,\n",
    "                                            batch_size=32)\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    for i_trials in i_trials_in_batch:\n",
    "        # Have to add empty fourth dimension to X\n",
    "        batch_X = train_set.X[i_trials][:,:,:,None]\n",
    "        batch_y = train_set.y[i_trials]\n",
    "        net_in = np_to_var(batch_X)\n",
    "        if cuda:\n",
    "            net_in = net_in.cuda()\n",
    "        net_target = np_to_var(batch_y)\n",
    "        if cuda:\n",
    "            net_target = net_target.cuda()\n",
    "        # Remove gradients of last backward pass from all parameters\n",
    "        optimizer.zero_grad()\n",
    "        # Compute outputs of the network\n",
    "        outputs = model(net_in)\n",
    "        # Compute the loss\n",
    "        loss = F.nll_loss(outputs, net_target)\n",
    "        # Do the backpropagation\n",
    "        loss.backward()\n",
    "        # Update parameters with the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print some statistics each epoch\n",
    "    model.eval()\n",
    "    print(\"Epoch {:d}\".format(i_epoch))\n",
    "    for setname, dataset in (('Train', train_set), ('Test', test_set)):\n",
    "        i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, batch_size=32, shuffle=False)\n",
    "        outputs = []\n",
    "        net_targets = []\n",
    "        for i_trials in i_trials_in_batch:\n",
    "            batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "            batch_y = dataset.y[i_trials]\n",
    "            \n",
    "            net_in = np_to_var(batch_X)\n",
    "            if cuda:\n",
    "                net_in = net_in.cuda()\n",
    "            net_target = np_to_var(batch_y)\n",
    "            if cuda:\n",
    "                net_target = net_target.cuda()\n",
    "            net_target = var_to_np(net_target)\n",
    "            output = var_to_np(model(net_in))\n",
    "            outputs.append(output)\n",
    "            net_targets.append(net_target)\n",
    "        net_targets = np_to_var(np.concatenate(net_targets))\n",
    "        outputs = np_to_var(np.concatenate(outputs))\n",
    "        loss = F.nll_loss(outputs, net_targets)\n",
    "        print(\"{:6s} Loss: {:.5f}\".format(\n",
    "            setname, float(var_to_np(loss))))\n",
    "        predicted_labels = np.argmax(var_to_np(outputs), axis=1)\n",
    "        accuracy = np.mean(dataset.y  == predicted_labels)\n",
    "        print(\"{:6s} Accuracy: {:.1f}%\".format(\n",
    "            setname, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aR1blMkOQZLk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "1 - Two-Classes Classification (BNCI) Colab.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
