{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-71bbb5e04559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingFileList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# read file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0md1T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingFileList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0md1E\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidationFileList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Torchpy35/lib/python3.5/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[1;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Torchpy35/lib/python3.5/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Format dataset, we read the file for the desired subject, and parse the data to extract:\n",
    "- samplingRate\n",
    "- trialLength\n",
    "- X, a M x N x K matrix, which stands for trial x chan x samples\n",
    "                         the actual values are 160 x 15 x 2560\n",
    "- y, a M vector containing the labels {0,1}\n",
    "\n",
    "ref:\n",
    "Dataset description: https://lampx.tugraz.at/~bci/database/002-2014/description.pdf\n",
    "\"\"\"\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sys \n",
    "import mne\n",
    "\n",
    "# prepare data containers\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "trainingFileList = ['../BBCIData/S14T.mat', \n",
    "                    '../BBCIData/S13T.mat', \n",
    "                    '../BBCIData/S12T.mat', \n",
    "                    '../BBCIData/S11T.mat', \n",
    "                    '../BBCIData/S10T.mat', \n",
    "                    '../BBCIData/S09T.mat', \n",
    "                    '../BBCIData/S08T.mat', \n",
    "                    '../BBCIData/S07T.mat', \n",
    "                    '../BBCIData/S06T.mat', \n",
    "                    '../BBCIData/S05T.mat', \n",
    "                    '../BBCIData/S04T.mat', \n",
    "                    '../BBCIData/S03T.mat', \n",
    "                    '../BBCIData/S02T.mat', \n",
    "                    '../BBCIData/S01T.mat']\n",
    "\n",
    "validationFileList = ['../BBCIData/S14E.mat', \n",
    "                      '../BBCIData/S13E.mat', \n",
    "                      '../BBCIData/S12E.mat', \n",
    "                      '../BBCIData/S11E.mat', \n",
    "                      '../BBCIData/S10E.mat', \n",
    "                      '../BBCIData/S09E.mat', \n",
    "                      '../BBCIData/S08E.mat', \n",
    "                      '../BBCIData/S07E.mat', \n",
    "                      '../BBCIData/S06E.mat', \n",
    "                      '../BBCIData/S05E.mat', \n",
    "                      '../BBCIData/S04E.mat', \n",
    "                      '../BBCIData/S03E.mat', \n",
    "                      '../BBCIData/S02E.mat', \n",
    "                      '../BBCIData/S01E.mat']\n",
    "\n",
    "\n",
    "\n",
    "trainingFileList = ['../BBCIData/S14T.mat']\n",
    "\n",
    "validationFileList = ['../BBCIData/S14E.mat']\n",
    "\n",
    "def filterData(rawData, samplingRate):\n",
    "    print(rawData.shape)\n",
    "    \n",
    "    #filteredData = mne.filter.filter_data()\n",
    "    \n",
    "    filterHandle = mne.filter.create_filter(rawData[0,:], samplingRate, l_freq=7., h_freq=35., fir_design='firwin')  \n",
    "    filterHalfLenght = len(filterHandle) // 2\n",
    "\n",
    "    filteredData = np.zeros([rawData.shape[0],rawData.shape[1]+filterHalfLenght])\n",
    "\n",
    "    # for each channel\n",
    "    for i in range(rawData.shape[0]):\n",
    "        #filteredData[i,:] = mne.filter.filter_data(rawData[i,:],sfreq=samplingRate ,l_freq=7., h_freq=35.,method='iir')\n",
    "        filteredData[i,:] = np.convolve(filterHandle, rawData[i,:])[len(filterHandle) // 2:]\n",
    "\n",
    "    filteredData = filteredData[:,filterHalfLenght:-filterHalfLenght]\n",
    "    return filteredData\n",
    "    \n",
    "\n",
    "\n",
    "tStart = 3.5\n",
    "tStop = 5.\n",
    "\n",
    "for i in range(len(trainingFileList)):\n",
    "    # read file\n",
    "    d1T = sio.loadmat(trainingFileList[i])\n",
    "    d1E = sio.loadmat(validationFileList[i])\n",
    "    \n",
    "    samplingRate = d1T['data'][0][0][0][0][3][0][0]\n",
    "    trialLength = (int)(tStop*samplingRate)\n",
    "\n",
    "\n",
    "    # run through all training runs\n",
    "    for run in range(5):\n",
    "        y.append(d1T['data'][0][run][0][0][2][0]) # labels\n",
    "        timestamps = d1T['data'][0][run][0][0][1][0] # timestamps\n",
    "        rawData = d1T['data'][0][run][0][0][0].transpose() # chan x data\n",
    "        \n",
    "        rawData = filterData(rawData,samplingRate)\n",
    "        \n",
    "        # parse out data based on timestamps\n",
    "        for start in timestamps:\n",
    "            dstart = (int)(start + tStart*samplingRate)\n",
    "            end = start + trialLength\n",
    "            X.append(rawData[:,dstart:end]) #15 x 2560\n",
    "\n",
    "\n",
    "    # run through all validation runs (we do not discriminate at this point)\n",
    "    for run in range(3):\n",
    "        y.append(d1E['data'][0][run][0][0][2][0]) # labels\n",
    "        timestamps = d1E['data'][0][run][0][0][1][0] # timestamps\n",
    "        rawData = d1E['data'][0][run][0][0][0].transpose() # chan x data\n",
    "\n",
    "        filterData(rawData,samplingRate)\n",
    "        \n",
    "        # parse out data based on timestamps\n",
    "        for start in timestamps:\n",
    "            dstart = (int)(start + tStart*samplingRate)\n",
    "            end = start + trialLength\n",
    "            X.append(rawData[:,dstart:end]) #15 x 2557\n",
    "\n",
    "    del rawData\n",
    "    del d1T\n",
    "    del d1E\n",
    "\n",
    "# arrange data into numpy arrays\n",
    "# also torch expect float32 for samples\n",
    "# and int64 for labels {0,1}\n",
    "X = np.array(X).astype(np.float32)\n",
    "y = (np.array(y).flatten()-1).astype(np.int64)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# erase unused references\n",
    "d1T = []\n",
    "d1E = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-66793bef5b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# pick some components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mepochs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from brainDecodeMOABBWrapper.SkLearnBrainDecode import SkLearnBrainDecode\n",
    "\n",
    "#from pyriemann.estimation import XdawnCovariances\n",
    "#from pyriemann.tangentspace import TangentSpace\n",
    "#from pyriemann.utils.viz import plot_confusion_matrix\n",
    "#from pyriemann.estimation import Covariances\n",
    "#from pyriemann.classification import TSclassifier, MDM\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from random import randint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# Decoding in tangent space with a logistic regression\n",
    "\n",
    "n_components = 2  # pick some components\n",
    "\n",
    "labels = y\n",
    "epochs_data = X\n",
    "\n",
    "\n",
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "cv = KFold(len(labels), 10, shuffle=True, random_state=randint(1,5000))\n",
    "\n",
    "print(\"epoch data:\")\n",
    "print(epochs_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifer = SkLearnBrainDecode()\n",
    "\n",
    "\n",
    "preds = np.zeros(len(labels))\n",
    "\n",
    "print(\"labels:\")\n",
    "print(labels.shape)\n",
    "\n",
    "for train_idx, test_idx in cv:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    classifer.fit(epochs_data[train_idx], y_train)\n",
    "    #preds[test_idx] = clf.predict(epochs_data[test_idx])\n",
    "\n",
    "# Printing the results\n",
    "#acc = np.mean(preds == labels)\n",
    "#print(\"Classification accuracy: %f \" % (acc))\n",
    "\n",
    "#names = ['audio left', 'audio right', 'vis left', 'vis right']\n",
    "#plot_confusion_matrix(preds, labels, names)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
