{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 15, 2560)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Format dataset, we read the file for the desired subject, and parse the data to extract:\n",
    "- samplingRate\n",
    "- trialLength\n",
    "- X, a M x N x K matrix, which stands for trial x chan x samples\n",
    "                         the actual values are 160 x 15 x 2560\n",
    "- y, a M vector containing the labels {0,1}\n",
    "\n",
    "ref:\n",
    "Dataset description: https://lampx.tugraz.at/~bci/database/002-2014/description.pdf\n",
    "\"\"\"\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# prepare data containers\n",
    "y = []\n",
    "X = []\n",
    "\"\"\"\n",
    "trainingFileList = ['BBCIData/S14T.mat', \n",
    "                    'BBCIData/S13T.mat', \n",
    "                    'BBCIData/S12T.mat', \n",
    "                    'BBCIData/S11T.mat', \n",
    "                    'BBCIData/S10T.mat', \n",
    "                    'BBCIData/S09T.mat', \n",
    "                    'BBCIData/S08T.mat', \n",
    "                    'BBCIData/S07T.mat', \n",
    "                    'BBCIData/S06T.mat', \n",
    "                    'BBCIData/S05T.mat', \n",
    "                    'BBCIData/S04T.mat', \n",
    "                    'BBCIData/S03T.mat', \n",
    "                    'BBCIData/S02T.mat', \n",
    "                    'BBCIData/S01T.mat']\n",
    "\n",
    "validationFileList = ['BBCIData/S14E.mat', \n",
    "                      'BBCIData/S13E.mat', \n",
    "                      'BBCIData/S12E.mat', \n",
    "                      'BBCIData/S11E.mat', \n",
    "                      'BBCIData/S10E.mat', \n",
    "                      'BBCIData/S09E.mat', \n",
    "                      'BBCIData/S08E.mat', \n",
    "                      'BBCIData/S07E.mat', \n",
    "                      'BBCIData/S06E.mat', \n",
    "                      'BBCIData/S05E.mat', \n",
    "                      'BBCIData/S04E.mat', \n",
    "                      'BBCIData/S03E.mat', \n",
    "                      'BBCIData/S02E.mat', \n",
    "                      'BBCIData/S01E.mat']\n",
    "\"\"\"\n",
    "\n",
    "trainingFileList = ['BBCIData/S14T.mat']\n",
    "\n",
    "validationFileList = ['BBCIData/S14E.mat']\n",
    "\n",
    "for i in range(len(trainingFileList)):\n",
    "    # read file\n",
    "    d1T = sio.loadmat(trainingFileList[i])\n",
    "    d1E = sio.loadmat(validationFileList[i])\n",
    "    \n",
    "    samplingRate = d1T['data'][0][0][0][0][3][0][0]\n",
    "    trialLength = 5*samplingRate\n",
    "\n",
    "\n",
    "    # run through all training runs\n",
    "    for run in range(5):\n",
    "        y.append(d1T['data'][0][run][0][0][2][0]) # labels\n",
    "        timestamps = d1T['data'][0][run][0][0][1][0] # timestamps\n",
    "        rawData = d1T['data'][0][run][0][0][0].transpose() # chan x data\n",
    "\n",
    "        # parse out data based on timestamps\n",
    "        for start in timestamps:\n",
    "            end = start + trialLength\n",
    "            X.append(rawData[:,start:end]) #15 x 2560\n",
    "\n",
    "\n",
    "    # run through all validation runs (we do not discriminate at this point)\n",
    "    for run in range(3):\n",
    "        y.append(d1E['data'][0][run][0][0][2][0]) # labels\n",
    "        timestamps = d1E['data'][0][run][0][0][1][0] # timestamps\n",
    "        rawData = d1E['data'][0][run][0][0][0].transpose() # chan x data\n",
    "\n",
    "        # parse out data based on timestamps\n",
    "        for start in timestamps:\n",
    "            end = start + trialLength\n",
    "            X.append(rawData[:,start:end]) #15 x 2560\n",
    "\n",
    "    del rawData\n",
    "    del d1T\n",
    "    del d1E\n",
    "\n",
    "# arrange data into numpy arrays\n",
    "# also torch expect float32 for samples\n",
    "# and int64 for labels {0,1}\n",
    "X = np.array(X).astype(np.float32)\n",
    "y = (np.array(y).flatten()-1).astype(np.int64)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# erase unused references\n",
    "d1T = []\n",
    "d1E = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch data:\n",
      "(160, 15, 2560)\n",
      "labels:\n",
      "(160,)\n",
      "Classification accuracy: 0.568750 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "====================================================================\n",
    "ERP EEG decoding in Tangent space.\n",
    "====================================================================\n",
    "Decoding applied to EEG data in sensor space decomposed using Xdawn.\n",
    "After spatial filtering, covariances matrices are estimated, then projected in\n",
    "the tangent space and classified with a logistic regression.\n",
    "\"\"\"\n",
    "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# Decoding in tangent space with a logistic regression\n",
    "\n",
    "n_components = 2  # pick some components\n",
    "\n",
    "labels = y\n",
    "epochs_data = X\n",
    "\n",
    "\n",
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "cv = KFold(len(labels), 10, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"epoch data:\")\n",
    "print(epochs_data.shape)\n",
    "\n",
    "\n",
    "clf = make_pipeline(XdawnCovariances(n_components),\n",
    "                    TangentSpace(metric='riemann'),\n",
    "                    LogisticRegression())\n",
    "\n",
    "preds = np.zeros(len(labels))\n",
    "\n",
    "print(\"labels:\")\n",
    "print(labels.shape)\n",
    "\n",
    "for train_idx, test_idx in cv:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    clf.fit(epochs_data[train_idx], y_train)\n",
    "    preds[test_idx] = clf.predict(epochs_data[test_idx])\n",
    "\n",
    "# Printing the results\n",
    "acc = np.mean(preds == labels)\n",
    "print(\"Classification accuracy: %f \" % (acc))\n",
    "\n",
    "#names = ['audio left', 'audio right', 'vis left', 'vis right']\n",
    "#plot_confusion_matrix(preds, labels, names)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subject 1\n",
    "# Classification accuracy: 0.531250 \n",
    "\n",
    "# subject 2\n",
    "# Classification accuracy: 0.656250 \n",
    "\n",
    "# subject 3\n",
    "# Classification accuracy: 0.843750 \n",
    "\n",
    "# subject 4\n",
    "# Classification accuracy: 0.625000 \n",
    "\n",
    "# subject 5\n",
    "# Classification accuracy: 0.568750 \n",
    "\n",
    "# subject 6\n",
    "# Classification accuracy: 0.656250 \n",
    "\n",
    "# subject 7\n",
    "# Classification accuracy: 0.793750 \n",
    "\n",
    "# subject 8\n",
    "# Classification accuracy: 0.587500 \n",
    "\n",
    "# subject 9\n",
    "# Classification accuracy: 0.556250\n",
    "\n",
    "# subject 10\n",
    "# Classification accuracy: 0.581250\n",
    "\n",
    "# subject 11\n",
    "# Classification accuracy: 0.593750\n",
    "\n",
    "# subject 12\n",
    "# Classification accuracy: 0.556250\n",
    "\n",
    "# subject 13\n",
    "# Classification accuracy: 0.581250\n",
    "\n",
    "# subject 14\n",
    "# Classification accuracy: 0.568750\n",
    "\n",
    "# subject 1-14\n",
    "# Classification accuracy: 0.542411 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
